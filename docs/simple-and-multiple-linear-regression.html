<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Topic 1 Simple and multiple linear regression | Getting started with Quantitative Research Methods and R</title>
  <meta name="description" content="These are some of the course materials for the Goldsmiths’ Core Quantitative Research Methods course. It is a living document that will be added to regularly." />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Topic 1 Simple and multiple linear regression | Getting started with Quantitative Research Methods and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are some of the course materials for the Goldsmiths’ Core Quantitative Research Methods course. It is a living document that will be added to regularly." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Topic 1 Simple and multiple linear regression | Getting started with Quantitative Research Methods and R" />
  
  <meta name="twitter:description" content="These are some of the course materials for the Goldsmiths’ Core Quantitative Research Methods course. It is a living document that will be added to regularly." />
  

<meta name="author" content="Lukas Wallrich" />


<meta name="date" content="2020-03-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="accessing-online-data-sources.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="include\psyteachr.css" type="text/css" />
<link rel="stylesheet" href="include\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Getting started with Quantitative Research Methods and R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#further-sources"><i class="fa fa-check"></i><b>0.1</b> Further sources</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html"><i class="fa fa-check"></i><b>1</b> Simple and multiple linear regression</a>
<ul>
<li class="chapter" data-level="1.1" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#simple-linear-regression"><i class="fa fa-check"></i><b>1.1</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#plotting-a-simple-linear-regression-model"><i class="fa fa-check"></i><b>1.1.1</b> Plotting a simple linear regression model</a></li>
<li class="chapter" data-level="1.1.2" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#mathematical-representation-of-a-simple-linear-regression-model"><i class="fa fa-check"></i><b>1.1.2</b> Mathematical representation of a simple linear regression model</a></li>
<li class="chapter" data-level="1.1.3" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#fitting-a-simple-linear-regression-model-in-r"><i class="fa fa-check"></i><b>1.1.3</b> Fitting a simple linear regression model in R</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#bivariate-correlation"><i class="fa fa-check"></i><b>1.2</b> Bivariate correlation</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#calculating-the-correlation-coefficient"><i class="fa fa-check"></i><b>1.2.1</b> Calculating the correlation coefficient</a></li>
<li class="chapter" data-level="1.2.2" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#equivalence-to-linear-regression"><i class="fa fa-check"></i><b>1.2.2</b> Equivalence to linear regression</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>1.3</b> Multiple linear regression</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#dummy-coding-revisited"><i class="fa fa-check"></i><b>1.3.1</b> Dummy coding revisited</a></li>
<li class="chapter" data-level="1.3.2" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#mathematical-structure-of-multiple-linear-models"><i class="fa fa-check"></i><b>1.3.2</b> Mathematical structure of multiple linear models</a></li>
<li class="chapter" data-level="1.3.3" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#running-multiple-linear-regression-models-in-r"><i class="fa fa-check"></i><b>1.3.3</b> Running multiple linear regression models in R</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#comparing-means-between-conditions-or-groups"><i class="fa fa-check"></i><b>1.4</b> Comparing means between conditions or groups</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#repeated-measures-or-independent-samples"><i class="fa fa-check"></i><b>1.4.1</b> Repeated measures or independent samples</a></li>
<li class="chapter" data-level="1.4.2" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#two-independent-means"><i class="fa fa-check"></i><b>1.4.2</b> Two independent means</a></li>
<li class="chapter" data-level="1.4.3" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#two-dependent-means"><i class="fa fa-check"></i><b>1.4.3</b> Two dependent means</a></li>
<li class="chapter" data-level="1.4.4" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#more-than-two-independent-means"><i class="fa fa-check"></i><b>1.4.4</b> More than two independent means</a></li>
<li class="chapter" data-level="1.4.5" data-path="simple-and-multiple-linear-regression.html"><a href="simple-and-multiple-linear-regression.html#more-than-two-means-from-repeated-measures"><i class="fa fa-check"></i><b>1.4.5</b> More than two means from repeated measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="accessing-online-data-sources.html"><a href="accessing-online-data-sources.html"><i class="fa fa-check"></i><b>2</b> Accessing online data sources</a>
<ul>
<li class="chapter" data-level="2.1" data-path="accessing-online-data-sources.html"><a href="accessing-online-data-sources.html#world-bank-data"><i class="fa fa-check"></i><b>2.1</b> World Bank data</a></li>
<li class="chapter" data-level="2.2" data-path="accessing-online-data-sources.html"><a href="accessing-online-data-sources.html#wikidata"><i class="fa fa-check"></i><b>2.2</b> Wikidata</a></li>
<li class="chapter" data-level="2.3" data-path="accessing-online-data-sources.html"><a href="accessing-online-data-sources.html#other-data-sources"><i class="fa fa-check"></i><b>2.3</b> Other data sources</a></li>
</ul></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="two-more-pipes.html"><a href="two-more-pipes.html"><i class="fa fa-check"></i><b>A</b> Two more pipes</a></li>
<li class="chapter" data-level="B" data-path="expanding-the-tidyverse-the-exposition-pipe.html"><a href="expanding-the-tidyverse-the-exposition-pipe.html"><i class="fa fa-check"></i><b>B</b> Expanding the tidyverse: the exposition pipe (<code>%$%</code>)</a></li>
<li class="chapter" data-level="C" data-path="a-somewhat-risky-time-saver-the-assignment-pipe.html"><a href="a-somewhat-risky-time-saver-the-assignment-pipe.html"><i class="fa fa-check"></i><b>C</b> A somewhat risky time-saver: the assignment pipe (<code>%&lt;&gt;%</code>)</a></li>
<li class="divider"></li>
<li><a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/" 
    target="blank"><img alt="Creative Commons License" 
    style="border-width:0" 
    src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><li>
<li><a href="https://psyteachr.github.io/" target="blank">PsyTeachR</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Getting started with Quantitative Research Methods and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-and-multiple-linear-regression" class="section level1" number="1">
<h1><span class="header-section-number">Topic 1</span> Simple and multiple linear regression</h1>
<p>This document recaps how we assess relationships between variables. It is work in progress and will be updated as we explore some further tests and special cases in the weeks to come.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="simple-and-multiple-linear-regression.html#cb1-1"></a><span class="kw">library</span>(tidyverse)</span></code></pre></div>
<div id="simple-linear-regression" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Simple linear regression</h2>
<p><a href="https://youtu.be/uoMjSFApBTY"><img src="https://i1.pngguru.com/preview/158/556/881/tuts-icon-youtube-alt-png-clipart.jpg?display=inline-block" id="id" class="class" width="35" height="35" /></a>   For an introduction to simple linear regression and correlation, <a href="https://youtu.be/uoMjSFApBTY">watch/rewatch this video</a></p>
<p>When considering the relationship between two continuous variables, we should always start with a scatterplot - for example, of the relationship between social trust and life satisfaction at the national level in European countries (data from the European Social Survey 2014).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="simple-and-multiple-linear-regression.html#cb2-1"></a><span class="co">#Data preparation</span></span>
<span id="cb2-2"><a href="simple-and-multiple-linear-regression.html#cb2-2"></a>ess &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="kw">url</span>(<span class="st">&quot;http://empower-training.de/Gold/round7.RDS&quot;</span>))</span>
<span id="cb2-3"><a href="simple-and-multiple-linear-regression.html#cb2-3"></a>ess &lt;-<span class="st"> </span>ess <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">soctrust =</span> (ppltrst <span class="op">+</span><span class="st"> </span>pplfair <span class="op">+</span><span class="st"> </span>pplhlp)<span class="op">/</span><span class="dv">3</span>)</span>
<span id="cb2-4"><a href="simple-and-multiple-linear-regression.html#cb2-4"></a>nat_avgs &lt;-<span class="st"> </span>ess <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(cntry) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb2-5"><a href="simple-and-multiple-linear-regression.html#cb2-5"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">nat_soctrust =</span> <span class="kw">mean</span>(soctrust, <span class="dt">na.rm=</span>T), </span>
<span id="cb2-6"><a href="simple-and-multiple-linear-regression.html#cb2-6"></a>            <span class="dt">nat_stflife =</span> <span class="kw">mean</span>(stflife, <span class="dt">na.rm=</span>T))</span>
<span id="cb2-7"><a href="simple-and-multiple-linear-regression.html#cb2-7"></a></span>
<span id="cb2-8"><a href="simple-and-multiple-linear-regression.html#cb2-8"></a><span class="kw">ggplot</span>(nat_avgs, <span class="kw">aes</span>(<span class="dt">x=</span>nat_soctrust, <span class="dt">y=</span>nat_stflife)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-3"></span>
<img src="03-linear-regression_files/figure-html/unnamed-chunk-3-1.png" alt="**CAPTION THIS FIGURE!!**" width="100%" />
<p class="caption">
Figure 1.1: <strong>CAPTION THIS FIGURE!!</strong>
</p>
</div>
<p>The scatterplot can now help us to think about what kind of model would help us to explain or predict one variable based on the other. If a straight-line relationship seems reasonable, we can use a linear model.</p>
<div id="plotting-a-simple-linear-regression-model" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Plotting a simple linear regression model</h3>
<p>Geometrically, a simple linear regression model is just a straight line through the scatterplot, fitted in a way that minimises the distances from the points to the line. It can be fitted with the <code>geom_smooth(method="lm")</code> function.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="simple-and-multiple-linear-regression.html#cb3-1"></a><span class="kw">ggplot</span>(nat_avgs, <span class="kw">aes</span>(<span class="dt">x=</span>nat_soctrust, <span class="dt">y=</span>nat_stflife)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb3-2"><a href="simple-and-multiple-linear-regression.html#cb3-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-4"></span>
<img src="03-linear-regression_files/figure-html/unnamed-chunk-4-1.png" alt="**CAPTION THIS FIGURE!!**" width="100%" />
<p class="caption">
Figure 1.2: <strong>CAPTION THIS FIGURE!!</strong>
</p>
</div>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="simple-and-multiple-linear-regression.html#cb4-1"></a>    <span class="co">#se=FALSE hides confidence bands that are often just visual clutter</span></span></code></pre></div>
<p>For each value of one variable, this line now allows us to find the corresponding expected value of the other variable.</p>
</div>
<div id="mathematical-representation-of-a-simple-linear-regression-model" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Mathematical representation of a simple linear regression model</h3>
<p>The idea of a simple linear regression model is to link one predictor variable, <span class="math inline">\(x\)</span>, to an outcome variable, <span class="math inline">\(y\)</span>. Their relationship can be expressed in a simple formula:
<span class="math display">\[y=\beta_{0} +  \beta_{1}*x\]</span>
Here, <strong><span class="math inline">\(\beta_{1}\)</span> is the most important parameter</strong> - it tells us, how much a change of 1 in the <span class="math inline">\(x\)</span>-variable affects the <span class="math inline">\(y\)</span>-variable. Geometrically, it is the slope of the regression line. <span class="math inline">\(\beta_{0}\)</span> is the intercept of that line, i.e. the value of <span class="math inline">\(y\)</span> when <span class="math inline">\(x\)</span> is 0 - since <span class="math inline">\(x\)</span> can often not be zero, that parameter tends to be of little interest on its own.</p>
</div>
<div id="fitting-a-simple-linear-regression-model-in-r" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Fitting a simple linear regression model in R</h3>
<p>Linear models are fitted in R using the <code>lm()</code> function. The model itself is specified as a formula with the notation <code>y ~ x</code> where the <code>~</code> means ‘is predicted by’ and the intercept is added automatically.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="simple-and-multiple-linear-regression.html#cb5-1"></a><span class="kw">lm</span>(nat_stflife <span class="op">~</span><span class="st"> </span>nat_soctrust, <span class="dt">data =</span> nat_avgs) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = nat_stflife ~ nat_soctrust, data = nat_avgs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.86854 -0.35172  0.00667  0.30745  0.85047 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    2.7767     0.7311   3.798  0.00122 ** 
## nat_soctrust   0.8025     0.1347   5.957 9.84e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4633 on 19 degrees of freedom
## Multiple R-squared:  0.6513, Adjusted R-squared:  0.6329 
## F-statistic: 35.49 on 1 and 19 DF,  p-value: 9.839e-06</code></pre>
<p>In the summary, the first column of the coefficients table gives the estimates for
<span class="math inline">\(\beta_{0}\)</span> (in the intercept row) and <span class="math inline">\(\beta_{1}\)</span> (in the nat_soctrust row). Thus in this case, the regression formula could be written as:</p>
<p><span class="math display">\[LifeSatisfaction = 2.76 +  0.80 * SocialTrust\]</span>
Clearly this formula does not allow us to perfectly predict one variable from the other; we have already seen in the graph that not all points fall exactly on the line. The distances between each point and the line are the <strong>residuals</strong> - their distribution is described at the top of the <code>summary()</code>-function output.</p>
<div id="interpreting-r2" class="section level4" number="1.1.3.1">
<h4><span class="header-section-number">1.1.3.1</span> Interpreting <span class="math inline">\(R^2\)</span></h4>
<p>The model output allows us to say how well the line fits by considering the <span class="math inline">\(R^2\)</span> value. It is based on the sum of the squares of the deviations of each data point from either the mean (<span class="math inline">\(SS_{total}\)</span>) or the model(<span class="math inline">\(SS_{residual}\)</span>).</p>
<p>If I was considering a model that predicted people’s height, I might have a person who is 1.6m tall. If the mean of the data was 1.8m, their squared total deviation would be <span class="math inline">\(0.2*0.2 = 0.04\)</span>. If the model then predicted their height at 1.55m, their squared residual deviation would be <span class="math inline">\(-0.05*-0.05 = 0.025\)</span>. Once this is summed up for all data points, <span class="math inline">\(R^2\)</span> is calculated with the following formula:
<span class="math display">\[R^2 = 1 - \frac{SS_{residual}}{SS_{total}}\]</span></p>
<p>Given that the sum of squared residuals can never be less than 0 or more than the sum of the total residuals, <span class="math inline">\(R^2\)</span> can only take up values between 0 and 1. It can be understood as the share of total variance explained by the model (or to link it to the formula: as the total variance minus the share <em>not</em> explained by the model).</p>
</div>
<div id="interpreting-prt-the-p-value" class="section level4" number="1.1.3.2">
<h4><span class="header-section-number">1.1.3.2</span> Interpreting Pr(&gt;|t|), the <em>p</em>-value</h4>
<p>Each coefficient comes with an associated <em>p</em>-value in the summary that is shown at the end of the row. As indicated by the column title, it indicates the probability that the test statistic would be this large or larger <em>if</em> the null hypothesis was true and there was no association in the underlying population.</p>
<p>As per usual, we would typically report coefficients with a <em>p</em>-value below .05 as statistically significant. The significance level for the intercept is almost never relevant and thus not reported (it simply tests whether the value of y would be different from 0 when x is zero, which is rarely of particular interest).</p>
</div>
</div>
</div>
<div id="bivariate-correlation" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Bivariate correlation</h2>
<p>Simple linear regression can tell us whether two variables are linearly related to each other, whether this finding is statistically significant (i.e. unlikely to have arisen due to change), and how strong the relationship is <em>in terms of the units of the two variables.</em> Quite often, however, we would prefer a standardised measure of the strength of a relationship, and a quicker test. That is where correlation comes in.</p>
<p>The <strong>Pearson’s correlation coefficient</strong> is the slope of the regression line when both variables are standardised, i.e. expressed in units of their standard deviations (as so-called Z-scores). It is again bounded, between -1 and 1, and as it is unit-free, it can give quick information as to which relationships matter more and which matter less.</p>
<div id="calculating-the-correlation-coefficient" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Calculating the correlation coefficient</h3>
<p>Before calculating a correlation coefficient, <strong>you need to look at the scatterplot and make sure that a straight-line relationship looks reasonable.</strong> If that is the case, you can use the <code>cor.test()</code> function to calculate the correlation coefficient.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="simple-and-multiple-linear-regression.html#cb7-1"></a><span class="kw">cor.test</span>(nat_avgs<span class="op">$</span>nat_soctrust, nat_avgs<span class="op">$</span>nat_stflife) </span>
<span id="cb7-2"><a href="simple-and-multiple-linear-regression.html#cb7-2"></a><span class="co">#If you have missing data, use the na.rm = TRUE argument to have it excluded before the calculation</span></span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  nat_avgs$nat_soctrust and nat_avgs$nat_stflife
## t = 5.957, df = 19, p-value = 9.839e-06
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.5760041 0.9186640
## sample estimates:
##       cor 
## 0.8070221</code></pre>
<p>The estimated cor at the very bottom is the correlation coefficient, usually reported as <em>r</em> = .81. This shows that there is a strong positive relationship between the two variables. Check the <em>p</em>-value to see whether the relationship is statistically significant and the 95%-confidence interval to see how precise the estimate is likely to be.</p>
</div>
<div id="equivalence-to-linear-regression" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Equivalence to linear regression</h3>
<p>Just to show that this is indeed equivalent to simple linear regression on the standardised variables, which can be calculated using the <code>scale()</code>-function.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="simple-and-multiple-linear-regression.html#cb9-1"></a><span class="kw">ggplot</span>(nat_avgs, <span class="kw">aes</span>(<span class="dt">x=</span><span class="kw">scale</span>(nat_soctrust), <span class="dt">y=</span><span class="kw">scale</span>(nat_stflife))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb9-2"><a href="simple-and-multiple-linear-regression.html#cb9-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-7"></span>
<img src="03-linear-regression_files/figure-html/unnamed-chunk-7-1.png" alt="**CAPTION THIS FIGURE!!**" width="100%" />
<p class="caption">
Figure 1.3: <strong>CAPTION THIS FIGURE!!</strong>
</p>
</div>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="simple-and-multiple-linear-regression.html#cb10-1"></a><span class="kw">lm</span>(<span class="kw">scale</span>(nat_stflife) <span class="op">~</span><span class="st"> </span><span class="kw">scale</span>(nat_soctrust), <span class="dt">data =</span> nat_avgs) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = scale(nat_stflife) ~ scale(nat_soctrust), data = nat_avgs)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.13572 -0.45992  0.00872  0.40203  1.11209 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         1.524e-16  1.322e-01   0.000        1    
## scale(nat_soctrust) 8.070e-01  1.355e-01   5.957 9.84e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6059 on 19 degrees of freedom
## Multiple R-squared:  0.6513, Adjusted R-squared:  0.6329 
## F-statistic: 35.49 on 1 and 19 DF,  p-value: 9.839e-06</code></pre>
<p>Note that the regression coefficient for the scaled variable is now exactly identical to the correlation coefficient shown above.</p>
</div>
</div>
<div id="multiple-linear-regression" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Multiple linear regression</h2>
<p>Linear models can easily be extended to multiple predictor variables. Here I will focus on a few key points that particularly focus on linear models that include categorical predictor variables.</p>
<p><a href="https://youtu.be/6lcDzTlsGVE"><img src="https://i1.pngguru.com/preview/158/556/881/tuts-icon-youtube-alt-png-clipart.jpg?display=inline-block" id="id" class="class" width="35" height="35" /></a>   You can <a href="https://youtu.be/6lcDzTlsGVE">watch/rewatch this video</a> this video to take you through the conceptual process and some examples step-by-step.</p>
<div id="dummy-coding-revisited" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Dummy coding revisited</h3>
<p>Multiple linear regression models often use categorical predictors. However, they need to be turned into numbers. This is done through automatic dummy coding, which creates variables coded as 0 and 1.</p>
<p>Note that dummy coding always results in <strong>one fewer dummy variable than the number of levels of the categorical variable</strong>. For example, a gender variable with two levels (male/female) would be recoded into a single dummy variable <em>female</em> (0=no, 1=yes). Note that there is no equivalent variable <em>male</em> as that would be redundant. Given that the hypothetical gender variable here is defined as either male or female, not female necessarily implies male.</p>
<p>The same applies to larger number of levels - see how three possible values for the department variabel can be recoded into two dummy variables:
<img src="./W10Dummy.png" alt="Dummy coding example" /></p>
<p>The level that is not explicitly mentioned anymore is the <strong>reference level</strong>. In a linear model, that is what all other effects are compared to, so it is important to keep in mind which that is.</p>
</div>
<div id="mathematical-structure-of-multiple-linear-models" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Mathematical structure of multiple linear models</h3>
<p>Linear models are characterised by intercepts and slopes. Geometrically, intercepts shift a line or plane along an axis, while a slope changes its orientation in space. Conceptually, intercepts are like on/off switches, while slopes indicate what happens when variables are dialed up or down.</p>
<p>For example, we might want to predict life expectancy based on a person’s gender and their level of physical activity. Then the model would be</p>
<p><span class="math display">\[LifeExpectancy=\beta_{0} +  \beta_{1}*female + \beta_{2}*activity\]</span>
<span class="math inline">\(\beta_{0}\)</span> here would describe the notional life expectancy of males without any activity, <span class="math inline">\(\beta_{0}+\beta_{1}\)</span> would describe that of females without any exercise - so both of these are intercepts, the <span class="math inline">\(female\)</span> variable simply determines which intercept we choose. <span class="math inline">\(\beta_{2}\)</span> is now the effect of each unit of activity, i.e. the slope of the regression line.</p>
</div>
<div id="running-multiple-linear-regression-models-in-r" class="section level3" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Running multiple linear regression models in R</h3>
<p>In the <code>lm()</code>-function, it is very easy to keep on adding predictors to the formula by just using the <code>+</code>-symbol. For example, we can consider the UK General Election Results in 2019 and see what helps explain the vote share of the Conservatives.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="simple-and-multiple-linear-regression.html#cb12-1"></a><span class="co">#Load and prep data</span></span>
<span id="cb12-2"><a href="simple-and-multiple-linear-regression.html#cb12-2"></a>constituencies &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="kw">url</span>(<span class="st">&quot;http://empower-training.de/Gold/ConstituencyData2019.csv&quot;</span>), <span class="dt">col_types =</span> <span class="st">&quot;_cfddddfffddddfffdfdddd&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: 168 parsing failures.
## row                    col expected actual         file
##  47 ConShare2017           a double   #N/A &lt;connection&gt;
## 534 ConShare2017           a double   #N/A &lt;connection&gt;
## 534 ShareReligious         a double   #N/A &lt;connection&gt;
## 534 ShareChristian         a double   #N/A &lt;connection&gt;
## 534 DeprivationRankEngland a double   #N/A &lt;connection&gt;
## ... ...................... ........ ...... ............
## See problems(...) for more details.</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="simple-and-multiple-linear-regression.html#cb14-1"></a>constituencies &lt;-<span class="st"> </span>constituencies <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(RegionName <span class="op">!=</span><span class="st"> &quot;Northern Ireland&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb14-2"><a href="simple-and-multiple-linear-regression.html#cb14-2"></a><span class="st">          </span><span class="kw">mutate</span>(<span class="dt">nation =</span> <span class="kw">case_when</span>(RegionName <span class="op">==</span><span class="st"> &quot;Scotland&quot;</span> <span class="op">~</span><span class="st"> &quot;Scotland&quot;</span>,</span>
<span id="cb14-3"><a href="simple-and-multiple-linear-regression.html#cb14-3"></a>                                    RegionName <span class="op">==</span><span class="st"> &quot;Wales&quot;</span> <span class="op">~</span><span class="st"> &quot;Wales&quot;</span>,</span>
<span id="cb14-4"><a href="simple-and-multiple-linear-regression.html#cb14-4"></a>                                    T <span class="op">~</span><span class="st"> &quot;England&quot;</span>))  <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb14-5"><a href="simple-and-multiple-linear-regression.html#cb14-5"></a><span class="st">          </span><span class="kw">filter</span>(ConstituencyName <span class="op">!=</span><span class="st"> &quot;Chorley&quot;</span>)</span>
<span id="cb14-6"><a href="simple-and-multiple-linear-regression.html#cb14-6"></a></span>
<span id="cb14-7"><a href="simple-and-multiple-linear-regression.html#cb14-7"></a><span class="co">#Simple linear regression model:</span></span>
<span id="cb14-8"><a href="simple-and-multiple-linear-regression.html#cb14-8"></a><span class="kw">lm</span>(ElectionConShare <span class="op">~</span><span class="st"> </span>MedianAge, <span class="dt">data =</span> constituencies) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ElectionConShare ~ MedianAge, data = constituencies)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.41131 -0.09130  0.01502  0.10007  0.30207 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.252020   0.040956  -6.153 1.35e-09 ***
## MedianAge    0.017104   0.001003  17.054  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1384 on 629 degrees of freedom
## Multiple R-squared:  0.3162, Adjusted R-squared:  0.3151 
## F-statistic: 290.8 on 1 and 629 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We now know that the Conservative vote share seems to be strongly related to the median age of the constituency, and can find and interpret the coefficient estimate (1.7 pct-points per year of median age), significance value and <span class="math inline">\(R^2\)</span> as above. What happens when we add nation, to account for differences between Scotland, England and Wales?</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="simple-and-multiple-linear-regression.html#cb16-1"></a><span class="co">#Declare nation as factor and then set the reference level for categorical predictors</span></span>
<span id="cb16-2"><a href="simple-and-multiple-linear-regression.html#cb16-2"></a>constituencies<span class="op">$</span>nation &lt;-<span class="st"> </span><span class="kw">factor</span>(constituencies<span class="op">$</span>nation) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">relevel</span>(<span class="dt">ref =</span> <span class="st">&quot;England&quot;</span>)</span>
<span id="cb16-3"><a href="simple-and-multiple-linear-regression.html#cb16-3"></a><span class="kw">lm</span>(ElectionConShare <span class="op">~</span><span class="st"> </span>MedianAge <span class="op">+</span><span class="st"> </span>nation, <span class="dt">data =</span> constituencies) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ElectionConShare ~ MedianAge + nation, data = constituencies)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.37287 -0.06969  0.00687  0.07799  0.27545 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    -0.2777133  0.0337157  -8.237 1.03e-15 ***
## MedianAge       0.0185574  0.0008295  22.373  &lt; 2e-16 ***
## nationScotland -0.2527752  0.0156649 -16.136  &lt; 2e-16 ***
## nationWales    -0.1493447  0.0187193  -7.978 7.08e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1138 on 627 degrees of freedom
## Multiple R-squared:  0.5392, Adjusted R-squared:  0.537 
## F-statistic: 244.6 on 3 and 627 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Now we have a more complex model. Based on the coefficient estimates, we would now estimate the vote share as follows
<span class="math display">\[VoteShare=-0.27 +  0.018*age + -0.25*Scotland + -0.15*Wales\]</span>
The figures for Scotland and Wales need to be compared to the unnamed reference level, i.e. to England - so we would expect a Scottish constituency to have a 25 percentage points lower Conservative vote share <em>when keeping median age constant.</em> Likewise, we now would expect an increase of the median age by 1 year to increase the Conservative vote share by 1.8 percentage points, <em>keeping the effect of nation constant.</em></p>
<div id="significance-testing-and-reporting-in-multiple-regression-models" class="section level4" number="1.3.3.1">
<h4><span class="header-section-number">1.3.3.1</span> Significance testing and reporting in multiple regression models</h4>
<p>With more than one predictor, we have two questions:</p>
<ul>
<li>is the <strong>overall model</strong> significant, i.e. can we confidently believe that its estimates are better than if we just took the overall mean as our estimate for each constituency? That is shown in the last line of the summary. Here we would report that the regression model predicting the conservative vote share per constituency based on its median age and the nation it was located in was significant, with <em>F</em>(3, 627) = 244.6, <em>p</em> &lt; .001, and explained a substantial share of the variance, <span class="math inline">\(R^2\)</span> = .54.</li>
<li>does <strong>each predictor</strong> explain a significant share of unique variance? That is shown at the end of each line in the coefficients table, with many predictors it would usually be reported in a table.</li>
</ul>

</div>
</div>
</div>
<div id="comparing-means-between-conditions-or-groups" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Comparing means between conditions or groups</h2>
<p><a href="https://youtu.be/L69HyBnvQRQ"><img src="https://i1.pngguru.com/preview/158/556/881/tuts-icon-youtube-alt-png-clipart.jpg?display=inline-block" id="id" class="class" width="35" height="35" /></a>   <a href="https://youtu.be/L69HyBnvQRQ">Watch/rewatch this video</a> for an introduction to testing for differences between two means and to the differences between repeated measures and independent samples designs.</p>
<p><a href="https://youtu.be/r96FYPLQ1l0"><img src="https://i1.pngguru.com/preview/158/556/881/tuts-icon-youtube-alt-png-clipart.jpg?display=inline-block" id="id" class="class" width="35" height="35" /></a>   <a href="https://youtu.be/r96FYPLQ1l0">Watch/rewatch this video</a> for an introduction to testing for differences between <em>more than</em> two means.</p>
<div id="repeated-measures-or-independent-samples" class="section level3" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Repeated measures or independent samples</h3>
<p>The first question always needs to be whether each participant contributes one or several data points to the dependent variable that is compared. If they contribute only one, we have an <em>independent samples</em> or <em>between-participants</em> design; if they contribute several, the design is <em>repeated measures</em> or <em>within participants.</em> In the latter case, we need to account for the relationships between some of the measurements in our analysis.</p>
</div>
<div id="two-independent-means" class="section level3" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Two independent means</h3>
<p>Going back to the European Social Survey 2014 data, we might be curious whether social trust differs between men and women in the UK. For that, we should always first calculate the descriptive statistics:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="simple-and-multiple-linear-regression.html#cb18-1"></a>ess &lt;-<span class="st"> </span><span class="kw">read_rds</span>(<span class="kw">url</span>(<span class="st">&quot;http://empower-training.de/Gold/round7.RDS&quot;</span>))</span>
<span id="cb18-2"><a href="simple-and-multiple-linear-regression.html#cb18-2"></a>ess &lt;-<span class="st"> </span>ess <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">soctrust =</span> (ppltrst <span class="op">+</span><span class="st"> </span>pplfair <span class="op">+</span><span class="st"> </span>pplhlp)<span class="op">/</span><span class="dv">3</span>)</span>
<span id="cb18-3"><a href="simple-and-multiple-linear-regression.html#cb18-3"></a>essUK &lt;-<span class="st"> </span>ess <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(cntry<span class="op">==</span><span class="st">&quot;GB&quot;</span>)</span>
<span id="cb18-4"><a href="simple-and-multiple-linear-regression.html#cb18-4"></a>essUK <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(gndr) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="kw">mean</span>(soctrust, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   gndr   `mean(soctrust, na.rm = TRUE)`
##   &lt;fct&gt;                           &lt;dbl&gt;
## 1 Male                             5.70
## 2 Female                           5.72</code></pre>
<p>Those means look very close. Nevertheless, we might want to know how likely we would have been to see a difference this large under the null-hypothesis, i.e. if social trust did not differ between men and women. For that, we can run a t-test.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="simple-and-multiple-linear-regression.html#cb20-1"></a><span class="kw">t.test</span>(soctrust <span class="op">~</span><span class="st"> </span>gndr, <span class="dt">data=</span>essUK, <span class="dt">var.equal =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  soctrust by gndr
## t = -0.2116, df = 2248, p-value = 0.8324
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.1601569  0.1289597
## sample estimates:
##   mean in group Male mean in group Female 
##             5.702288             5.717886</code></pre>
<p>This is just a special case of a linear model, so we could also use the <code>lm()</code> function:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="simple-and-multiple-linear-regression.html#cb22-1"></a><span class="kw">lm</span>(soctrust <span class="op">~</span><span class="st"> </span>gndr, <span class="dt">data=</span>essUK) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = soctrust ~ gndr, data = essUK)
## 
## Residuals:
## &lt;Labelled double&gt;: Most people can be trusted or you can&#39;t be too careful
##     Min      1Q  Median      3Q     Max 
## -5.7179 -1.0512  0.2821  1.2821  4.2977 
## 
## Labels:
##  value                      label
##      0   You can&#39;t be too careful
##      1                          1
##      2                          2
##      3                          3
##      4                          4
##      5                          5
##      6                          6
##      7                          7
##      8                          8
##      9                          9
##     10 Most people can be trusted
##  NA(b)                    Refusal
##  NA(c)                 Don&#39;t know
##  NA(d)                  No answer
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  5.70229    0.05450 104.623   &lt;2e-16 ***
## gndrFemale   0.01560    0.07372   0.212    0.832    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.741 on 2248 degrees of freedom
##   (14 observations deleted due to missingness)
## Multiple R-squared:  1.992e-05,  Adjusted R-squared:  -0.0004249 
## F-statistic: 0.04478 on 1 and 2248 DF,  p-value: 0.8324</code></pre>
<p>Both show, as expected, that the difference we observed could easily have been due to chance. If this is the only test you conduct, you would conventionally usually report the result of the t-test, saying: there was no significant difference in social trust between men and women, <em>t</em>(2248) = -0.21, <em>p</em> = .83.</p>
</div>
<div id="two-dependent-means" class="section level3" number="1.4.3">
<h3><span class="header-section-number">1.4.3</span> Two dependent means</h3>
<p>In the ESS data, participants were asked how much they drank when they last drank during a weekday and during a weekend. Here the same participants provided two alcohol measures, so that these data points represent repeated measures. If we ignore that in the analysis, we violate a key assumption of linear models - namely the independence of observations. Therefore, we need to use a paired t-test. But as always, first descriptive statistics.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="simple-and-multiple-linear-regression.html#cb24-1"></a>essUK <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="dt">weekday =</span> <span class="kw">mean</span>(alcwkdy, <span class="dt">na.rm=</span>T), <span class="dt">weekend=</span><span class="kw">mean</span>(alcwknd, <span class="dt">na.rm =</span> T)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">diff =</span> weekend <span class="op">-</span><span class="st"> </span>weekday)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   weekday weekend  diff
##     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1    36.3    62.4  26.1</code></pre>
<p>So there seems to be a large difference in the average amount people drink during a single session on weekdays and weekends. Is the difference statistically significant?</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="simple-and-multiple-linear-regression.html#cb26-1"></a><span class="kw">t.test</span>(essUK<span class="op">$</span>alcwknd, essUK<span class="op">$</span>alcwkdy, <span class="dt">paired =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  essUK$alcwknd and essUK$alcwkdy
## t = 13.119, df = 1800, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  22.23332 30.04986
## sample estimates:
## mean of the differences 
##                26.14159</code></pre>
<p>The paired t-test - as it says in the output - tests whether the mean of the differences between the two variables is significantly different from 0. We could also specify that condition directly:</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="simple-and-multiple-linear-regression.html#cb28-1"></a><span class="kw">t.test</span>(essUK<span class="op">$</span>alcwknd <span class="op">-</span><span class="st"> </span>essUK<span class="op">$</span>alcwkdy, <span class="dt">mu =</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  essUK$alcwknd - essUK$alcwkdy
## t = 13.119, df = 1800, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  22.23332 30.04986
## sample estimates:
## mean of x 
##  26.14159</code></pre>
</div>
<div id="more-than-two-independent-means" class="section level3" number="1.4.4">
<h3><span class="header-section-number">1.4.4</span> More than two independent means</h3>
<p>We might be interested whether levels of life satisfaction differ between the European countries we could reach by ferry from the UK. First, let’s look at the descriptive statistics.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="simple-and-multiple-linear-regression.html#cb30-1"></a>essF &lt;-<span class="st"> </span>ess <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(cntry <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;FR&quot;</span>, <span class="st">&quot;ES&quot;</span>, <span class="st">&quot;IE&quot;</span>, <span class="st">&quot;BE&quot;</span>, <span class="st">&quot;NL&quot;</span>))</span>
<span id="cb30-2"><a href="simple-and-multiple-linear-regression.html#cb30-2"></a>essF <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(cntry) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="kw">mean</span>(stflife, <span class="dt">na.rm =</span> T))</span></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   cntry `mean(stflife, na.rm = T)`
##   &lt;fct&gt;                      &lt;dbl&gt;
## 1 BE                          7.45
## 2 ES                          6.96
## 3 FR                          6.39
## 4 IE                          6.94
## 5 NL                          7.60</code></pre>
<p>There seem to be some differences - but are they statistically significant? Here we actually have two questions:</p>
<ul>
<li>do the countries together explain a significant share of the variance in life satisfaction? (<em>omnibus test</em>)</li>
<li>are the levels of life satisfaction in any two countries significantly different from each other? (<em>pairwise comparisons</em>)</li>
</ul>
<div id="omnibus-test-anova" class="section level4" number="1.4.4.1">
<h4><span class="header-section-number">1.4.4.1</span> Omnibus test (ANOVA)</h4>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="simple-and-multiple-linear-regression.html#cb32-1"></a><span class="co">#Set the reference level, so that we know what the coefficients mean</span></span>
<span id="cb32-2"><a href="simple-and-multiple-linear-regression.html#cb32-2"></a>essF<span class="op">$</span>cntry &lt;-<span class="st"> </span><span class="kw">factor</span>(essF<span class="op">$</span>cntry) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">relevel</span>(<span class="dt">ref =</span> <span class="st">&quot;FR&quot;</span>)</span>
<span id="cb32-3"><a href="simple-and-multiple-linear-regression.html#cb32-3"></a><span class="kw">lm</span>(stflife <span class="op">~</span><span class="st"> </span>cntry, <span class="dt">data =</span> essF) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = stflife ~ cntry, data = essF)
## 
## Residuals:
## &lt;Labelled double&gt;: How satisfied with life as a whole
##     Min      1Q  Median      3Q     Max 
## -7.6017 -0.9646  0.3983  1.3983  3.6054 
## 
## Labels:
##  value                  label
##      0 Extremely dissatisfied
##      1                      1
##      2                      2
##      3                      3
##      4                      4
##      5                      5
##      6                      6
##      7                      7
##      8                      8
##      9                      9
##     10    Extremely satisfied
##  NA(b)                Refusal
##  NA(c)             Don&#39;t know
##  NA(d)              No answer
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.39456    0.04612 138.663   &lt;2e-16 ***
## cntryBE      1.05711    0.06651  15.893   &lt;2e-16 ***
## cntryES      0.57006    0.06512   8.753   &lt;2e-16 ***
## cntryIE      0.54832    0.06192   8.856   &lt;2e-16 ***
## cntryNL      1.20711    0.06516  18.526   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.016 on 9896 degrees of freedom
##   (19 observations deleted due to missingness)
## Multiple R-squared:  0.04125,    Adjusted R-squared:  0.04086 
## F-statistic: 106.4 on 4 and 9896 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Here we just want to see whether the country variable explains a significant share of the variance. That is shown by the last line, so that we would report: There was an overall effects of country on life satisfaction, <em>F</em>(4, 9869) = 106.4, <em>p</em>&lt;.001.</p>
<p>If you are so inclined, note that this is identical to a one-way ANOVA. To see that, you can replace summary() by car::Anova() - however, this is only truly essential if you are a psychologist, most other disciplines prefer the plain linear models when they suffice.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="simple-and-multiple-linear-regression.html#cb34-1"></a><span class="kw">lm</span>(stflife <span class="op">~</span><span class="st"> </span>cntry, <span class="dt">data =</span> essF) <span class="op">%&gt;%</span><span class="st"> </span>car<span class="op">::</span><span class="kw">Anova</span>()</span></code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: stflife
##           Sum Sq   Df F value    Pr(&gt;F)    
## cntry       1730    4  106.45 &lt; 2.2e-16 ***
## Residuals  40218 9896                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="pairwise-comparisons" class="section level4" number="1.4.4.2">
<h4><span class="header-section-number">1.4.4.2</span> Pairwise comparisons</h4>
<p>Now that we know that some of the countries are different, we will want to locate the differences. That is where pairwise t-tests come in.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="simple-and-multiple-linear-regression.html#cb36-1"></a><span class="kw">pairwise.t.test</span>(essF<span class="op">$</span>stflife, essF<span class="op">$</span>cntry, <span class="dt">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  essF$stflife and essF$cntry 
## 
##    FR      BE      ES      IE     
## BE &lt; 2e-16 -       -       -      
## ES &lt; 2e-16 2.4e-12 -       -      
## IE &lt; 2e-16 1.0e-14 1.00    -      
## NL &lt; 2e-16 0.24    &lt; 2e-16 &lt; 2e-16
## 
## P value adjustment method: bonferroni</code></pre>
<p>This gives us <em>p</em>-values for all tests, that are adjusted for the fact that we are doing many (i.e. 10) comparisons and thus running a greater risk of getting a false positive. The bonferroni adjustment, selected here, multiplies each <em>p</em>-value by the number of comparisons, unless the resulting value would exceed 1 and thus be an impossible probability.</p>
<p>Combining this with the descriptive statistics, we can say, for instance, that the people in the Netherlands and Belgium are more satisfied with life than those in any of the other countries, but that their satisfaction levels do not differ significantly from each other.</p>
</div>
</div>
<div id="more-than-two-means-from-repeated-measures" class="section level3" number="1.4.5">
<h3><span class="header-section-number">1.4.5</span> More than two means from repeated measures</h3>
<p>Here I will revert to the simulated example from the video linked above. In that, the effect of four conditions during studying on test score was tested, namely whether participants were exposed to instrumental music, vocal music, white noise or silence.</p>
<p>Note that the data for repeated measures analaysis in R generally needs to be formatted in a way that each row shows one observation rather than multiple observations from one participant (“long” format). If you have data in a “wide” format, you can reshape it with the <code>gather()</code> function.</p>
<p>To analyse whether there are differences between the conditions, as always, we start with descriptive statistics.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="simple-and-multiple-linear-regression.html#cb38-1"></a>noiseData <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(condition) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summarise</span>(<span class="kw">mean</span>(score))</span></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   condition    `mean(score)`
##   &lt;chr&gt;                &lt;dbl&gt;
## 1 instrumental          11.6
## 2 silence               13.0
## 3 vocals                10.8
## 4 whiteNoise            13.5</code></pre>
<p>It looks like there are some differences, but to be able to judge statistical significance, we would again be interested in omnibus tests and then pairwise comparisons.</p>
<div id="omnibus-test" class="section level4" number="1.4.5.1">
<h4><span class="header-section-number">1.4.5.1</span> Omnibus test</h4>
<p>Testing whether the conditions make a difference is a little bit harder with repeated measures because the observations are not independent. Therefore, we need to run a model that takes into account the relationships between the observations taken from a single participant. This does not work with <code>lm()</code>; instead we need to use an additional package that allows for multi-level modeling where some observations are clustered together, <code>lme4</code> is the most frequently used such package for this purpose.</p>
<p>In the case of repeated measures, we were comparing our model with the group variable as a predictor implicitly to the model that only has the overall mean as a predictor (that is what the <code>lm()</code> F-test is doing). Here, the null model uses each participant’s own overall mean as the prediction for their performance in any one condition. We need to set up that null model explicitly and then compare it to the model that considers groups.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="simple-and-multiple-linear-regression.html#cb40-1"></a><span class="co">#install.packages(lme4)</span></span>
<span id="cb40-2"><a href="simple-and-multiple-linear-regression.html#cb40-2"></a><span class="kw">library</span>(lme4)</span></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre><code>## Registered S3 methods overwritten by &#39;lme4&#39;:
##   method                          from
##   cooks.distance.influence.merMod car 
##   influence.merMod                car 
##   dfbeta.influence.merMod         car 
##   dfbetas.influence.merMod        car</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="simple-and-multiple-linear-regression.html#cb45-1"></a><span class="co">#Set reference level explicitly</span></span>
<span id="cb45-2"><a href="simple-and-multiple-linear-regression.html#cb45-2"></a>noiseData<span class="op">$</span>condition &lt;-<span class="st"> </span>noiseData<span class="op">$</span>condition <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">factor</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">relevel</span>(<span class="st">&quot;silence&quot;</span>)</span>
<span id="cb45-3"><a href="simple-and-multiple-linear-regression.html#cb45-3"></a></span>
<span id="cb45-4"><a href="simple-and-multiple-linear-regression.html#cb45-4"></a><span class="co">#Run null model - predicting only an individual intercept per participant</span></span>
<span id="cb45-5"><a href="simple-and-multiple-linear-regression.html#cb45-5"></a>model0 &lt;-<span class="st"> </span><span class="kw">lmer</span>((score <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>participantID)),   <span class="dt">data =</span> noiseData)</span>
<span id="cb45-6"><a href="simple-and-multiple-linear-regression.html#cb45-6"></a></span>
<span id="cb45-7"><a href="simple-and-multiple-linear-regression.html#cb45-7"></a><span class="co">#Run hypothesized model - adding the groups as a predictor</span></span>
<span id="cb45-8"><a href="simple-and-multiple-linear-regression.html#cb45-8"></a>model1 &lt;-<span class="st"> </span><span class="kw">lmer</span>((score <span class="op">~</span><span class="st"> </span>condition <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>participantID)),   <span class="dt">data =</span> noiseData)</span>
<span id="cb45-9"><a href="simple-and-multiple-linear-regression.html#cb45-9"></a></span>
<span id="cb45-10"><a href="simple-and-multiple-linear-regression.html#cb45-10"></a><span class="co">#Comparing the two models</span></span>
<span id="cb45-11"><a href="simple-and-multiple-linear-regression.html#cb45-11"></a><span class="kw">anova</span>(model0, model1)</span></code></pre></div>
<pre><code>## refitting model(s) with ML (instead of REML)</code></pre>
<pre><code>## Data: noiseData
## Models:
## model0: score ~ (1 | participantID)
## model1: score ~ condition + (1 | participantID)
##        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)    
## model0  3 480.29 488.10 -237.14   474.29                             
## model1  6 447.31 462.94 -217.66   435.31 38.978      3  1.754e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Here we can see that the hypothesised model showed a significantly better fit. This is tested with a <span class="math inline">\(\chi^2\)</span>-test, which we will look at further later in the course.</p>
</div>
<div id="pairwise-comparisons-1" class="section level4" number="1.4.5.2">
<h4><span class="header-section-number">1.4.5.2</span> Pairwise comparisons</h4>
<p>Now that we know that there is a difference between some of the conditions, we will want to know which are different. For that, we can again run pairwise t-tests; we just need to specify that they are run on paired data by setting <code>paired = TRUE</code>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="simple-and-multiple-linear-regression.html#cb48-1"></a><span class="kw">pairwise.t.test</span>(noiseData<span class="op">$</span>score, noiseData<span class="op">$</span>condition,   <span class="dt">p.adj =</span> <span class="st">&quot;bonferroni&quot;</span>, <span class="dt">paired=</span><span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using paired t tests 
## 
## data:  noiseData$score and noiseData$condition 
## 
##              silence instrumental vocals 
## instrumental 0.045   -            -      
## vocals       8.2e-06 0.423        -      
## whiteNoise   1.000   0.001        2.0e-05
## 
## P value adjustment method: bonferroni</code></pre>
<p>This indicates that the scores of participants in the white noise and silence conditions were not significantly different from each other, while the other comparisons were significant.</p>

</div>
</div>
</div>
</div>
<div class="psyteachr_footer">
  
</div>
<script>

/* update total correct if #total_correct exists */
update_total_correct = function() {
  if (t = document.getElementById("total_correct")) {
    t.innerHTML =
      document.getElementsByClassName("correct").length + " of " +
      document.getElementsByClassName("solveme").length + " correct";
  }
}

/* solution button toggling function */
b_func = function() {
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "");
  }
  
  if (my_answer !== "" & real_answers.includes(my_answer)) {
    cl.add("correct");
  } else {
    cl.remove("correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol){
    var tol = JSON.parse(this.dataset.tol);  
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("correct");
    } else {
      cl.remove("correct");
    }  
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("correct");
    }  
  }
  
  update_total_correct();
}

window.onload = function() {
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('solution')) {
      buttons[i].onclick = b_func;
    }
  }
  
  /* set up solveme inputs */
  var solveme = document.getElementsByClassName("solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off"); 
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";
    
    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;
    
    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  update_total_correct();
}

</script>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="accessing-online-data-sources.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"],
"google": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": {},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
